{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Libraries**\n",
        "\n"
      ],
      "metadata": {
        "id": "XlKYsOiteBtX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "VcT7qxgGd1OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Link to Drive*"
      ],
      "metadata": {
        "id": "J8ZRJ5TleSIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc4fVDkWeLV8",
        "outputId": "308b4ada-f0ff-480e-8a74-e542c7bf3196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4jyXHfWeg8r",
        "outputId": "ebc6455a-6b42-4ce6-ff4b-358194a0c42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'1606757129-chapter-1(1) (2).pptx'\n",
            "'Ch 1.ppt'\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            "'Correct Predictions Only (1).gsheet'\n",
            "'Correct Predictions Only.gsheet'\n",
            "'database book Elmasri.pdf'\n",
            " data.csv\n",
            " DBMS_Keys.pdf\n",
            "\"I am sharing 'Chapter_2_v8.0-1' with you\"\n",
            "'James F. Kurose_ Keith Ross - 7th edition A Top-Down Approach-Pearson (2016).pdf'\n",
            " lab4.docx\n",
            "'Lab Manual 01 (Installation).gdoc'\n",
            "'Lab Manual 01 (Installation).pdf'\n",
            "'Lab Manual 02 (Ubuntu Linux Commands).gdoc'\n",
            "'Lab Manual 02 (Ubuntu Linux Commands).pdf'\n",
            "'Lec 1.pptx'\n",
            "'OS Assignment:1.gdoc'\n",
            "'OS lab4 (1).docx'\n",
            "'OS lab4 (2).docx'\n",
            "'OS lab4.docx'\n",
            "'Preprocessed Sentiment Data (1).gsheet'\n",
            "'Preprocessed Sentiment Data (2).gsheet'\n",
            "'Preprocessed Sentiment Data (3).gsheet'\n",
            "'Preprocessed Sentiment Data (4).gsheet'\n",
            "'Preprocessed Sentiment Data (5).gsheet'\n",
            "'Preprocessed Sentiment Data.gsheet'\n",
            "'Preprocessed Sentiment Data.xlsx'\n",
            "'Python Certificate.jpg'\n",
            " sentiment_dataset_120.csv\n",
            " sentiment_dataset_120.gsheet\n",
            "'sentiment_dataset_sample (1).csv'\n",
            " sentiment_dataset_sample.csv\n",
            "'Sentiment Testing Set (1).gsheet'\n",
            "'Sentiment Testing Set (2).gsheet'\n",
            "'Sentiment Testing Set (3).gsheet'\n",
            "'Sentiment Testing Set (4).gsheet'\n",
            "'Sentiment Testing Set.gsheet'\n",
            "'Sentiment Test Set with Predictions (1).gsheet'\n",
            "'Sentiment Test Set with Predictions and Confidence.gsheet'\n",
            "'Sentiment Test Set with Predictions.gsheet'\n",
            "'Sentiment Training Set (1).gsheet'\n",
            "'Sentiment Training Set (2).gsheet'\n",
            "'Sentiment Training Set (3).gsheet'\n",
            "'Sentiment Training Set (4).gsheet'\n",
            "'Sentiment Training Set.gsheet'\n",
            "'Token-Level Sentiment with Confidence (1).gsheet'\n",
            "'Token-Level Sentiment with Confidence.gsheet'\n",
            "'Training Project  (1).docx'\n",
            "'Training Project .gdoc'\n",
            "'Training Project .xlsx'\n",
            "'types of keys in dbms.pdf'\n",
            "'Untitled document.gdoc'\n",
            "'Untitled spreadsheet.xlsx'\n",
            "'Word-Level  from Preprocessed.gsheet'\n",
            "'Word-Level Sentiment from Preprocessed (1).gsheet'\n",
            "'Word-Level Sentiment from Preprocessed (2).gsheet'\n",
            "'Word-Level Sentiment from Preprocessed (3).gsheet'\n",
            "'Word-Level Sentiment from Preprocessed.gsheet'\n",
            "'Word-Level Sentiment Predictions (1).gsheet'\n",
            "'Word-Level Sentiment Predictions.gsheet'\n",
            "'Wrong Predictions Only (1).gsheet'\n",
            "'Wrong Predictions Only (2).gsheet'\n",
            "'Wrong Predictions Only (3).gsheet'\n",
            "'Wrong Predictions Only.gsheet'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gspread gspread_dataframe\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3flydr5emol",
        "outputId": "2549f680-a9f0-42bc-9f70-249a26d75b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.0)\n",
            "Requirement already satisfied: gspread_dataframe in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from gspread_dataframe) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread_dataframe) (1.17.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2025.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n"
      ],
      "metadata": {
        "id": "ghBBZRRXesbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your actual spreadsheet name\n",
        "spreadsheet_name = \"sentiment_dataset_120\"\n",
        "\n",
        "# Open the spreadsheet\n",
        "sh = gc.open(spreadsheet_name)\n",
        "\n",
        "# Access the first sheet\n",
        "worksheet = sh.sheet1\n"
      ],
      "metadata": {
        "id": "D_P83BBie6KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open your spreadsheet\n",
        "spreadsheet_name = \"sentiment_dataset_120\"  # Make sure there's no extra space\n",
        "spreadsheet = gc.open(spreadsheet_name)\n",
        "worksheet = spreadsheet.sheet1\n",
        "\n",
        "# Load sheet data into DataFrame\n",
        "df = pd.DataFrame(worksheet.get_all_records())\n",
        "\n",
        "# Optional preview\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8U11RBSe_PU",
        "outputId": "9388c0ed-cb7f-4e68-fb70-5de4cc25c015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Sentence  Sentiment  \\\n",
            "0                                           Sentence  Sentiment   \n",
            "1          I had an amazing time at the beach today!   Positive   \n",
            "2  The customer service was incredibly helpful an...   Positive   \n",
            "3       This phone has exceeded all my expectations.   Positive   \n",
            "4    I'm really proud of how the project turned out.   Positive   \n",
            "\n",
            "                                 cleaned_text  \n",
            "0                                    sentence  \n",
            "1                    amazing time beach today  \n",
            "2  customer service incredibly helpful polite  \n",
            "3                 phone exceeded expectations  \n",
            "4              im really proud project turned  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "JFhD00Oafkif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess Function\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^a-z\\s]', '', text)\n",
        "        words = text.split()\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        words = [word for word in words if word not in stop_words]\n",
        "        return ' '.join(words)\n",
        "    return \"\""
      ],
      "metadata": {
        "id": "XZm342tofHvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages if not already installed\n",
        "!pip install --upgrade gspread gspread_dataframe google-auth\n",
        "\n",
        "# Import libraries\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Authenticate with Google Sheets\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# Load your Google Spreadsheet\n",
        "spreadsheet_name = 'sentiment_dataset_120'  # Make sure the name matches exactly\n",
        "spreadsheet = gc.open(spreadsheet_name)\n",
        "worksheet = spreadsheet.sheet1\n",
        "\n",
        "# Load data from the spreadsheet into a DataFrame\n",
        "df = pd.DataFrame(worksheet.get_all_records())\n",
        "\n",
        "# Preprocess function\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^a-z\\s]', '', text)  # Remove punctuation, numbers, symbols\n",
        "        words = text.split()\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        words = [word for word in stop_words if word not in stop_words]\n",
        "        return ' '.join(words)\n",
        "    return \"\"\n",
        "\n",
        "# Apply preprocessing\n",
        "df['preprocessed_text'] = df['Sentence'].apply(preprocess_text)\n",
        "\n",
        "# Create new Google Sheet and upload\n",
        "new_sheet_name = 'Preprocessed Sentiment Data'\n",
        "sh = gc.create(new_sheet_name)\n",
        "worksheet = sh.sheet1\n",
        "set_with_dataframe(worksheet, df)\n",
        "\n",
        "# Share the sheet with your email\n",
        "your_email = 'zarmeenejeaz390@gmail.com'\n",
        "sh.share(your_email, perm_type='user', role='writer')\n",
        "\n",
        "# Output the link to the spreadsheet\n",
        "print(\"‚úÖ Sheet created and shared!\")\n",
        "print(f\"üîó Open your sheet: https://docs.google.com/spreadsheets/d/{sh.id}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "h9CcWorAfiFQ",
        "outputId": "3fe15974-6663-44de-b980-b1188cfa5c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.11/dist-packages (6.2.0)\n",
            "Requirement already satisfied: gspread_dataframe in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (2.38.0)\n",
            "Collecting google-auth\n",
            "  Downloading google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from gspread_dataframe) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from gspread_dataframe) (1.17.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->gspread_dataframe) (2025.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2025.4.26)\n",
            "Downloading google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-auth\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.38.0\n",
            "    Uninstalling google-auth-2.38.0:\n",
            "      Successfully uninstalled google-auth-2.38.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.39.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-2.39.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "09afccfb5f46444bb720aaba8649c58d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sheet created and shared!\n",
            "üîó Open your sheet: https://docs.google.com/spreadsheets/d/1gCXRKXUQ6t6uGi2waXSeK3WoDijMuDtHS-btNd2fIQE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Load the sheet into df\n",
        "spreadsheet_name = 'sentiment_dataset_120'  # Corrected name without leading space\n",
        "spreadsheet = gc.open(spreadsheet_name)\n",
        "worksheet = spreadsheet.sheet1\n",
        "df = pd.DataFrame(worksheet.get_all_records())\n",
        "\n",
        "# STEP 2: Preprocess the 'Sentence' column\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^a-z\\s]', '', text)\n",
        "        words = text.split()\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        words = [word for word in words if word not in stop_words]\n",
        "        return ' '.join(words)\n",
        "    return \"\"\n",
        "\n",
        "df['preprocessed_text'] = df['Sentence'].apply(preprocess_text)\n",
        "\n",
        "# STEP 3: Split the cleaned text into words and attach sentiment\n",
        "word_rows = []\n",
        "for index, row in df.iterrows():\n",
        "    sentiment = row['Sentiment']\n",
        "    text = row['preprocessed_text']\n",
        "    words = text.split()\n",
        "    for word in words:\n",
        "        word_rows.append({'Word': word, 'Sentiment': sentiment})\n",
        "\n",
        "# STEP 4: Upload word-level data to a new Google Sheet\n",
        "word_df = pd.DataFrame(word_rows)\n",
        "\n",
        "word_sh = gc.create('Word-Level Sentiment from Preprocessed')\n",
        "word_ws = word_sh.sheet1\n",
        "set_with_dataframe(word_ws, word_df)\n",
        "\n",
        "# STEP 5: Share the sheet\n",
        "your_email = 'zarmeenejeaz390@gmail.com'\n",
        "word_sh.share(your_email, perm_type='user', role='writer')\n",
        "\n",
        "# STEP 6: Output link\n",
        "print(\"‚úÖ Word-level sentiment sheet created and shared!\")\n",
        "print(f\"üîó View it: https://docs.google.com/spreadsheets/d/{word_sh.id}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvbfyZxSgFnu",
        "outputId": "9e546774-0188-4f6a-f155-458ca7eaee4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Word-level sentiment sheet created and shared!\n",
            "üîó View it: https://docs.google.com/spreadsheets/d/1LT0bD6y8fUEu37DNbun78TkX8g5hkIKRs3XnHKI5jz4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned_text'] = df['Sentence'].apply(preprocess_text)\n",
        "print(df[['Sentence', 'cleaned_text']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eii-KejQgRC-",
        "outputId": "a30d9aec-f6eb-4a67-c68f-671eeb859421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Sentence  \\\n",
            "0                                           Sentence   \n",
            "1          I had an amazing time at the beach today!   \n",
            "2  The customer service was incredibly helpful an...   \n",
            "3       This phone has exceeded all my expectations.   \n",
            "4    I'm really proud of how the project turned out.   \n",
            "\n",
            "                                 cleaned_text  \n",
            "0                                    sentence  \n",
            "1                    amazing time beach today  \n",
            "2  customer service incredibly helpful polite  \n",
            "3                 phone exceeded expectations  \n",
            "4              im really proud project turned  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train-Test Split & TF-IDF Vectorization"
      ],
      "metadata": {
        "id": "aWbK7ZFvggw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features & Target\n",
        "X = df['cleaned_text']\n",
        "y = df['Sentiment']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "tasBOn2hgZBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "MoO9p9Qlgpep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression Model\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model.fit(X_train_tfidf, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "4uSKlNjrgs8d",
        "outputId": "af68dd83-5337-48e7-94bd-74adb019603f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(class_weight='balanced', max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"‚ñ∏\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"‚ñæ\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Dataset"
      ],
      "metadata": {
        "id": "kwDL4CG1gxEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "# 1. Predict on the training data\n",
        "y_train_pred = model.predict(X_train_tfidf)\n",
        "\n",
        "# 2. Create a DataFrame with text, actual,\n",
        "results = pd.DataFrame({\n",
        "    'Text': X_train,\n",
        "    'Actual': y_train,\n",
        "})\n",
        "\n",
        "# 3. Authenticate and authorize Google Sheets access\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# 4. Create a new Google Sheet\n",
        "sheet = gc.create('Training Predictions Export')\n",
        "worksheet = sheet.sheet1\n",
        "\n",
        "# 5. Export DataFrame to the sheet\n",
        "set_with_dataframe(worksheet, results)\n",
        "\n",
        "# 6. Share the sheet with your email (change email if needed)\n",
        "sheet.share('zarmeenejeaz390@gmail.com', perm_type='user', role='writer')\n",
        "\n",
        "# 7. Print sheet link\n",
        "print(\"‚úÖ Training predictions exported successfully!\")\n",
        "print(f\"üìÑ Sheet link: https://docs.google.com/spreadsheets/d/{sheet.id}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9xynFpJg1Ki",
        "outputId": "2fdc763e-2b9a-4251-fc37-9395f7b40e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Training predictions exported successfully!\n",
            "üìÑ Sheet link: https://docs.google.com/spreadsheets/d/1LXRjhbQcAZtRYUqQeGoMlbqlaHKMs5xnDsPb0eDmBTs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Dataset"
      ],
      "metadata": {
        "id": "zIyK28NmiLSR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['cleaned_text']\n",
        "y = df['Sentiment']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000, stop_words='english')\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Train the model\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CawoMwIRiRdN",
        "outputId": "0a7a4593-db49-4f89-cb8b-87aae3e4ea6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.375\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.22      0.29      0.25         7\n",
            "     Neutral       0.57      0.44      0.50         9\n",
            "    Positive       0.38      0.43      0.40         7\n",
            "   Sentiment       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.38        24\n",
            "   macro avg       0.29      0.29      0.29        24\n",
            "weighted avg       0.39      0.38      0.38        24\n",
            "\n",
            "Confusion Matrix:\n",
            " [[2 1 4 0]\n",
            " [4 4 1 0]\n",
            " [2 2 3 0]\n",
            " [1 0 0 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "# (Assuming you already have this)\n",
        "output_df = pd.DataFrame({\n",
        "    'Text': X_test,\n",
        "    'Actual Sentiment': y_test,\n",
        "    'Predicted Sentiment': y_pred\n",
        "})\n",
        "\n",
        "# ‚úÖ Authenticate with Google\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# ‚úÖ Create a new Google Sheet named \"Dump Predictions\"\n",
        "sheet = gc.create('Dump Predictions')\n",
        "worksheet = sheet.sheet1\n",
        "\n",
        "# ‚úÖ Upload DataFrame to the sheet\n",
        "set_with_dataframe(worksheet, output_df)\n",
        "\n",
        "# ‚úÖ Share with your email\n",
        "sheet.share('zarmeenejeaz390@gmail.com', perm_type='user', role='writer')\n",
        "\n",
        "# ‚úÖ Output link to the Google Sheet\n",
        "print(\"‚úÖ Test predictions exported successfully!\")\n",
        "print(f\"üìÑ Sheet link: https://docs.google.com/spreadsheets/d/{sheet.id}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQAjqs-ih56e",
        "outputId": "c13a18b3-9992-4cfd-db22-b67cbf40a261"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Test predictions exported successfully!\n",
            "üìÑ Sheet link: https://docs.google.com/spreadsheets/d/1aqd3KTpZ3FYGjVLfQRSUR2nzKluagVNF5___X6F84ok\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions"
      ],
      "metadata": {
        "id": "McxPo15qj7ZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚úÖ Step 1: TF-IDF Vectorization\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_tfidf = vectorizer.fit_transform(X)\n",
        "\n",
        "# ‚úÖ Step 2: Train-Test Split (Fixed!)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ‚úÖ Step 3: Train the Model\n",
        "model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ‚úÖ Step 4: Map test data back to raw sentences\n",
        "# Get the test indices to find original sentences\n",
        "_, test_indices = train_test_split(df.index, test_size=0.2, random_state=42)\n",
        "df_test = df.loc[test_indices].reset_index(drop=True)\n",
        "\n",
        "# ‚úÖ Step 5: Predict only on test data\n",
        "rows = []\n",
        "class_labels = model.classes_\n",
        "\n",
        "for i, row in df_test.iterrows():\n",
        "    sentence = row['Sentence']\n",
        "    sentiment = row['Sentiment']\n",
        "    text = row['cleaned_text']\n",
        "    words = text.split()\n",
        "\n",
        "    token_list = []\n",
        "    confidence_list = []\n",
        "\n",
        "    for word in words:\n",
        "        word_tfidf = vectorizer.transform([word])\n",
        "        if word_tfidf.nnz == 0:\n",
        "            probs = [0] * len(class_labels)\n",
        "        else:\n",
        "            probs = model.predict_proba(word_tfidf)[0]\n",
        "            probs = [int(p * 100) for p in probs]\n",
        "\n",
        "        token_list.append(word)\n",
        "        confidence_list.append(str(probs))\n",
        "\n",
        "    # Sentence-level prediction\n",
        "    sentence_tfidf = vectorizer.transform([text])\n",
        "    sentence_prediction = model.predict(sentence_tfidf)[0]\n",
        "    sentence_confidence = model.predict_proba(sentence_tfidf)[0]\n",
        "    sentence_confidence = [int(p * 100) for p in sentence_confidence]\n",
        "\n",
        "    rows.append({\n",
        "        'sentence': sentence,\n",
        "        'sentiment': sentiment,\n",
        "        'prediction': sentence_prediction,\n",
        "        'token': token_list,\n",
        "        'confidence (positive, negative, neutral)': confidence_list,\n",
        "        'confidence (sentence)': str(sentence_confidence)\n",
        "    })\n",
        "\n",
        "import pandas as pd\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "# üîÅ Convert list of dicts to DataFrame\n",
        "output_df = pd.DataFrame(rows)\n",
        "\n",
        "# üßπ Flatten token/confidence columns for clean display in Sheets\n",
        "output_df['token'] = output_df['token'].apply(lambda x: ', '.join(x))\n",
        "output_df['confidence (positive, negative, neutral)'] = output_df['confidence (positive, negative, neutral)'].apply(lambda x: '; '.join(x))\n",
        "\n",
        "# ‚úÖ Authenticate Google Sheets access\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# ‚úÖ Create new sheet and upload\n",
        "sheet = gc.create('Sentence-Level Prediction Dump')\n",
        "worksheet = sheet.sheet1\n",
        "set_with_dataframe(worksheet, output_df)\n",
        "\n",
        "# ‚úÖ Share with your email\n",
        "sheet.share('zarmeenejeaz390@gmail.com', perm_type='user', role='writer')\n",
        "\n",
        "# ‚úÖ Print Sheet Link\n",
        "print(\"‚úÖ Predictions exported to Google Spreadsheet!\")\n",
        "print(f\"üìÑ Link: https://docs.google.com/spreadsheets/d/{sheet.id}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcEw8vKjj-Ve",
        "outputId": "301cbdee-381f-4429-df69-d0d175b658b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Predictions exported to Google Spreadsheet!\n",
            "üìÑ Link: https://docs.google.com/spreadsheets/d/1FqDPEwYYG-EHEMd54wRwGoBwAr_B18Cm7KBPEGAzb4M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# True Predictions"
      ],
      "metadata": {
        "id": "WLXHOL44lOCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gspread\n",
        "from google.auth import default\n",
        "import pandas as pd\n",
        "\n",
        "# ‚úÖ Authenticate and access Google Sheet\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# ‚úÖ Open the spreadsheet by name\n",
        "spreadsheet = gc.open('Sentence-Level Prediction Dump')\n",
        "worksheet = spreadsheet.sheet1\n",
        "\n",
        "# ‚úÖ Read the sheet data into a DataFrame\n",
        "df = pd.DataFrame(worksheet.get_all_records())\n",
        "\n",
        "# ‚úÖ Print correct predictions\n",
        "print(\"Correct predictions:\")\n",
        "for index, row in df.iterrows():\n",
        "    if row[\"sentiment\"] == row[\"prediction\"]:\n",
        "        print(f\" {row['sentence']}  {row['prediction']}\")\n",
        "import gspread\n",
        "from google.auth import default\n",
        "import pandas as pd\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "# ‚úÖ Authenticate and access Google Sheet\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# ‚úÖ Open the original spreadsheet\n",
        "spreadsheet = gc.open('Sentence-Level Prediction Dump')\n",
        "worksheet = spreadsheet.sheet1\n",
        "\n",
        "# ‚úÖ Read data into a DataFrame\n",
        "df = pd.DataFrame(worksheet.get_all_records())\n",
        "\n",
        "# ‚úÖ Filter correct predictions\n",
        "correct_df = df[df[\"sentiment\"] == df[\"prediction\"]]\n",
        "\n",
        "# ‚úÖ Create a new sheet for correct predictions\n",
        "correct_sheet = gc.create('Correct Predictions Output')\n",
        "correct_ws = correct_sheet.sheet1\n",
        "\n",
        "# ‚úÖ Upload the filtered DataFrame\n",
        "set_with_dataframe(correct_ws, correct_df)\n",
        "\n",
        "# ‚úÖ Share the new sheet\n",
        "correct_sheet.share('zarmeenejeaz390@gmail.com', perm_type='user', role='writer')\n",
        "\n",
        "# ‚úÖ Confirm and show link\n",
        "print(\"‚úÖ Correct predictions exported to Google Spreadsheet!\")\n",
        "print(f\"üìÑ Link: https://docs.google.com/spreadsheets/d/{correct_sheet.id}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXkRX2yNlEoQ",
        "outputId": "75a7128f-93e8-4644-cc06-a413ba0da832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct predictions:\n",
            " I'm really proud of how the project turned out.  Positive\n",
            " The weather ruined all our plans.  Negative\n",
            " Just finished a great workout‚Äîfeeling energized!  Positive\n",
            " I received a promotion today and I‚Äôm beyond excited!  Positive\n",
            " I have a dentist appointment tomorrow at noon.  Neutral\n",
            " The repair took forever and didn‚Äôt fix the issue.  Negative\n",
            " My vacation was absolutely perfect from start to finish.  Positive\n",
            " Lunch break starts at 1 PM.  Neutral\n",
            " They painted the wall a different color.  Neutral\n",
            "‚úÖ Correct predictions exported to Google Spreadsheet!\n",
            "üìÑ Link: https://docs.google.com/spreadsheets/d/10LQM-fanRkW_Nmm67ophtqTXx8We8sIupZbPKh4fAlI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wrong Predictions"
      ],
      "metadata": {
        "id": "NVeW2nc0m0sN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gspread\n",
        "from google.auth import default\n",
        "import pandas as pd\n",
        "\n",
        "# ‚úÖ Authenticate and access Google Sheets\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# ‚úÖ Open the prediction spreadsheet\n",
        "spreadsheet = gc.open('Sentence-Level Prediction Dump')\n",
        "worksheet = spreadsheet.sheet1\n",
        "\n",
        "# ‚úÖ Load data into a DataFrame\n",
        "df = pd.DataFrame(worksheet.get_all_records())\n",
        "\n",
        "# ‚úÖ Print wrong predictions\n",
        "print(\"Wrong predictions:\")\n",
        "for index, row in df.iterrows():\n",
        "    if row[\"sentiment\"] != row[\"prediction\"]:\n",
        "        print(f\" {row['sentence']}  {row['prediction']} (Expected: {row['sentiment']})\")\n",
        "import gspread\n",
        "from google.auth import default\n",
        "import pandas as pd\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "# ‚úÖ Authenticate and access Google Sheets\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# ‚úÖ Open the prediction spreadsheet\n",
        "spreadsheet = gc.open('Sentence-Level Prediction Dump')\n",
        "worksheet = spreadsheet.sheet1\n",
        "\n",
        "# ‚úÖ Load data into a DataFrame\n",
        "df = pd.DataFrame(worksheet.get_all_records())\n",
        "\n",
        "# ‚úÖ Filter wrong predictions\n",
        "wrong_df = df[df[\"sentiment\"] != df[\"prediction\"]]\n",
        "\n",
        "# ‚úÖ Create a new Google Sheet to store wrong predictions\n",
        "wrong_sheet = gc.create('Wrong Predictions Output')\n",
        "wrong_ws = wrong_sheet.sheet1\n",
        "\n",
        "# ‚úÖ Upload the wrong predictions DataFrame\n",
        "set_with_dataframe(wrong_ws, wrong_df)\n",
        "\n",
        "# ‚úÖ Share the new sheet with your email\n",
        "wrong_sheet.share('zarmeenejeaz390@gmail.com', perm_type='user', role='writer')\n",
        "\n",
        "# ‚úÖ Print link to the new sheet\n",
        "print(\"‚úÖ Wrong predictions exported to Google Spreadsheet!\")\n",
        "print(f\"üìÑ Link: https://docs.google.com/spreadsheets/d/{wrong_sheet.id}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKepb31Xl3q1",
        "outputId": "e3ff4581-0efa-49fe-f45c-3e28aa0a541c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrong predictions:\n",
            " No one showed up to the event.  Neutral (Expected: Negative)\n",
            " It's just another regular day at work.  Positive (Expected: Neutral)\n",
            " She answered the call after two rings.  Negative (Expected: Neutral)\n",
            " I feel drained and unmotivated.  Positive (Expected: Negative)\n",
            " Her encouragement really lifted my spirits.  Negative (Expected: Positive)\n",
            " They took a break after the first session.  Negative (Expected: Neutral)\n",
            " I'm feeling really disappointed with my test results.  Positive (Expected: Negative)\n",
            " She complimented my work, and it meant a lot.  Neutral (Expected: Positive)\n",
            " The train departs every 30 minutes from this station.  Positive (Expected: Neutral)\n",
            " Sentence  Negative (Expected: Sentiment)\n",
            " The meeting lasted for two hours.  Negative (Expected: Neutral)\n",
            " The website was updated last night.  Negative (Expected: Neutral)\n",
            " Nothing I do seems to be good enough.  Positive (Expected: Negative)\n",
            " Today‚Äôs meeting went better than I expected.  Neutral (Expected: Positive)\n",
            " The food was cold and tasteless.  Positive (Expected: Negative)\n",
            "‚úÖ Wrong predictions exported to Google Spreadsheet!\n",
            "üìÑ Link: https://docs.google.com/spreadsheets/d/1C0_vPmN5-bPJq7xYu6my_AkRGmi6Bd7gP8cDmUokX6c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Example: train a simple model\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(model, 'model.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1gqTNXz7pVI",
        "outputId": "b68f800e-72e1-4086-bffa-fbdf67de137c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('model.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "esQfwirr7uZI",
        "outputId": "906c5fe2-cad1-4b81-db36-1664d7a5f5c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7ab5dbe0-ac9c-4002-8afd-5d22ed851ea4\", \"model.pkl\", 991)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}